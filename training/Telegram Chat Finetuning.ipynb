{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f56fe2e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f949cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7aa4d3",
   "metadata": {},
   "source": [
    "## Load Telegram Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5223dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47902\n"
     ]
    }
   ],
   "source": [
    "#https://telegram.org/blog/export-and-more, select JSON\n",
    "\n",
    "with open('result.json', encoding=\"utf8\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "messages = data[\"messages\"] #messages is a list\n",
    "print(len(messages)) #47902 messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a07386",
   "metadata": {},
   "source": [
    "## Segmenting \"conversations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a76cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "new_convo_threshold_seconds = 3600 #a new conversation starts if 1 hr without further messages elapses after the last message from me\n",
    "telegram_name = \"Bing Wen\"\n",
    "\n",
    "#obtain date of messages\n",
    "for message in messages:\n",
    "    message[\"datetime\"] = datetime.strptime(message['date'], '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "def check_new_convo(previous_message, current_message):\n",
    "    return (previous_message[\"from\"] == telegram_name and \n",
    "            (current_message[\"datetime\"] - previous_message[\"datetime\"]).seconds > \n",
    "            new_convo_threshold_seconds)\n",
    "\n",
    "#this loop creates a list of conversations\n",
    "conversations = []\n",
    "for idx,message in enumerate(messages):\n",
    "    if (idx == 0) or check_new_convo(messages[idx-1],messages[idx]):\n",
    "        if idx > 0:\n",
    "            conversations.append(new_conversation)\n",
    "        new_conversation = []\n",
    "    new_conversation.append(message)\n",
    "    \n",
    "conversations = list(filter(lambda x: len(x) > 1, conversations)) #one-message conversations are not conversations\n",
    "print(len(conversations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d88d1",
   "metadata": {},
   "source": [
    "## Labelling messages within conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8e1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conversation in conversations:\n",
    "    for idx,message in enumerate(conversation):\n",
    "        if idx == (len(conversation)-1):\n",
    "            continue\n",
    "        if idx == 0: #if start of convo\n",
    "            message[\"prompt_start\"] = True #this is a start of a prompt\n",
    "            message[\"completion_start\"] = False\n",
    "        if message[\"from\"] != telegram_name and conversation[idx+1][\"from\"] == telegram_name: #if this is the end of the other party's messages\n",
    "            message[\"prompt_end\"] = True #it's end the of the prompt\n",
    "            conversation[idx+1][\"completion_start\"] = True #and the start of a completion\n",
    "        else:\n",
    "            message[\"prompt_end\"] = False\n",
    "            conversation[idx+1][\"completion_start\"] = False\n",
    "        if message[\"from\"] == telegram_name and conversation[idx+1][\"from\"] != telegram_name: #if this is the end of a string of my messages\n",
    "            message[\"completion_end\"] = True #it's the end of a completion\n",
    "            conversation[idx+1][\"prompt_start\"] = True #and the next line is a start of a new prompt\n",
    "        else:\n",
    "            message[\"completion_end\"] = False\n",
    "            conversation[idx+1][\"prompt_start\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d5ffe4",
   "metadata": {},
   "source": [
    "## Creating prompt-completion pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b916d26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9865 training pairs\n"
     ]
    }
   ],
   "source": [
    "training_pairs = []\n",
    "\n",
    "def get_line(message): #this function prepends \n",
    "    if message[\"from\"] == telegram_name:\n",
    "        name = \"Me\"\n",
    "    else:\n",
    "        name = \"They\"\n",
    "    if 'photo' in message: #handle image messages\n",
    "        text = '<IMAGE>'\n",
    "    else:\n",
    "        text = message[\"text\"]\n",
    "    if text:\n",
    "        try: #handling some weird situations where there are urls/entities in the text\n",
    "            if isinstance(text, list):\n",
    "                textStr = \"\"\n",
    "                for stuff in text:\n",
    "                    if isinstance(stuff, dict):\n",
    "                        textStr += stuff[\"text\"]\n",
    "                    else:\n",
    "                        textStr += stuff\n",
    "                text = textStr\n",
    "        except:\n",
    "            print(text)\n",
    "        return f\"{name}:{text}\\n\"\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "#this loop creates the multiple training examples from each example \n",
    "for conversation in conversations:\n",
    "    seed_pair = {\"prompt\": \"\", \"completion\":\"\"}\n",
    "    for message in conversation:\n",
    "        if message[\"prompt_start\"]:\n",
    "            key = \"prompt\"\n",
    "        elif message[\"completion_start\"]:\n",
    "            key = \"completion\"\n",
    "        new_line = get_line(message)\n",
    "        if new_line:\n",
    "            seed_pair[key] += get_line(message)\n",
    "        if message.get(\"completion_end\",True):\n",
    "            training_pairs.append(seed_pair.copy())\n",
    "            seed_pair[\"prompt\"] += seed_pair[\"completion\"]\n",
    "            seed_pair[\"completion\"] = \"\"\n",
    "\n",
    "#strip those pairs with no completions\n",
    "training_pairs = [pair for pair in training_pairs if len((pair[\"completion\"].rstrip())) > 0]\n",
    "\n",
    "print(f\"{len(training_pairs)} training pairs\") #9865 training pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15228e5c",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3611db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_sequence = \"<END>\"\n",
    "me_token = \"Me:\"\n",
    "acceptable_char_length = 1400\n",
    "min_prompt_length = 1400\n",
    "\n",
    "def truncate_prompt(prompt, completion):\n",
    "    if (len(prompt) + len(completion)) > acceptable_char_length:\n",
    "        length_for_prompt = max(acceptable_char_length - len(completion), min_prompt_length)\n",
    "        new_prompt = prompt[-length_for_prompt:]\n",
    "        lower = min(new_prompt.find(\"\\nMe:\"),new_prompt.find(\"\\nThey:\"))\n",
    "        new_prompt = new_prompt[lower+1:]\n",
    "        return new_prompt\n",
    "    else:\n",
    "        return prompt\n",
    "    \n",
    "char_counter = 0\n",
    "\n",
    "for pair in training_pairs:\n",
    "    # next two lines gets rid of the first me in the completion, and appends it to the prompt instead\n",
    "    pair['prompt'] += me_token\n",
    "    pair['completion'] = \" \"+me_token.join(pair['completion'].split(me_token)[1:])+stop_sequence\n",
    "    if len(pair['prompt']) + len(pair['completion']) > acceptable_char_length:\n",
    "        pair['prompt'] = truncate_prompt(pair['prompt'],pair['completion']) #truncates prompt if conversation too long, retaining the more recent messages\n",
    "    char_counter += (len(pair['prompt']) + len(pair['completion']))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165c2da",
   "metadata": {},
   "source": [
    "## Prep training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94029871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 9865 prompt-completion pairs\n",
      "- All prompts end with suffix `Me:`\n",
      "  WARNING: Some of your prompts contain the suffix `Me:` more than once. We strongly suggest that you review your prompts and add a unique suffix\n",
      "- All completions end with suffix `\\n<END>`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"fine_tuning.jsonl\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `Me:` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n<END>\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.3 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(training_pairs)\n",
    "df.to_json(\"fine_tuning.jsonl\", orient='records', lines=True)\n",
    "!openai tools fine_tunes.prepare_data -f fine_tuning.jsonl -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ee0b8",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f8af5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR KEY>\"\n",
    "!openai api fine_tunes.create -t \"fine_tuning.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afc956",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a628d8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " HAHAHAHA\n",
      "Me:I'm not sure if I have a definitive answer to that\n",
      "Me:But I think it's important to live life with purpose and meaning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.organization = \"<YOUR ORGANISATION KEY>\"\n",
    "openai.api_key = \"<YOUR API KEY>\"\n",
    "\n",
    "def get_chatbings_response(text):\n",
    "    prompt = \"They:\" + text + \"\\nMe:\"\n",
    "    stop_sequence = \"<END>\"\n",
    "    response = openai.Completion.create(\n",
    "        model=\"curie:ft-central-provident-fund-board-2023-01-23-07-14-12\", \n",
    "        prompt=prompt, \n",
    "        temperature=0.2, \n",
    "        max_tokens=100, \n",
    "        frequency_penalty=0.6,\n",
    "        presence_penalty=0.6,\n",
    "        stop = stop_sequence\n",
    "    )\n",
    "    return response.choices[0].text\n",
    "\n",
    "print(get_chatbings_response(\"What is the meaning of life?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
